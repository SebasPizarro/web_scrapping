!pip install -q praw python-dotenv pandas

# PASO 1

from dotenv import load_dotenv
import os

load_dotenv()

print(os.getenv("REDDIT_CLIENT_ID"))

import praw, os

reddit = praw.Reddit(
    client_id=os.getenv("REDDIT_CLIENT_ID"),
    client_secret=os.getenv("REDDIT_CLIENT_SECRET"),
    username=os.getenv("REDDIT_USERNAME"),
    password=os.getenv("REDDIT_PASSWORD"),
    user_agent=os.getenv("REDDIT_USER_AGENT"),
    ratelimit_seconds=60,
)

print("Autenticado como:", reddit.user.me())

# PASO 2

# Paso 1: traer posts de un solo subreddit para validar la conexión y el formato
import os, time
import pandas as pd
import praw


try:
    _ = reddit.user.me()  
except NameError:
    from dotenv import load_dotenv
    load_dotenv(override=True)
    reddit = praw.Reddit(
        client_id=os.getenv("REDDIT_CLIENT_ID"),
        client_secret=os.getenv("REDDIT_CLIENT_SECRET"),
        username=os.getenv("REDDIT_USERNAME"),
        password=os.getenv("REDDIT_PASSWORD"),
        user_agent=os.getenv("REDDIT_USER_AGENT"),
        ratelimit_seconds=60,
    )

print("Autenticado como:", reddit.user.me())

#Función para bajar posts

def fetch_posts(reddit, subreddit_name, limit=50, listing="hot"):

    sr = reddit.subreddit(subreddit_name)
    selector = {"hot": sr.hot, "new": sr.new, "top": sr.top, "rising": sr.rising}
    gen = selector.get(listing, sr.hot)(limit=limit)

    rows = []
    for s in gen:
        rows.append({
            "subreddit": subreddit_name,
            "post_id": s.id,
            "title": s.title,
            "author": str(s.author) if s.author else None,
            "created_utc": pd.to_datetime(s.created_utc, unit="s"),
            "score": s.score,
            "upvote_ratio": getattr(s, "upvote_ratio", None),
            "num_comments": s.num_comments,
            "url": s.url,
            "permalink": "https://www.reddit.com" + s.permalink,
            "over_18": s.over_18,
            "stickied": s.stickied,
        })
    return pd.DataFrame(rows).drop_duplicates(subset=["post_id"])


SUBREDDIT = "politics"   # "worldpolitics", "PoliticalDiscussion"
POSTS = 30
LISTING = "hot"

posts_df = fetch_posts(reddit, SUBREDDIT, limit=POSTS, listing=LISTING)
print(f"Subreddit: r/{SUBREDDIT} | Posts descargados: {posts_df.shape[0]}")
display(posts_df.head(10))

# Lista de subreddits políticos 
SUBREDDITS = [
    "politics",
    "worldpolitics",
    "PoliticalDiscussion",
    "Conservative",
    "Liberal"
]

POSTS_PER_SUB = 20   # posts de cada subreddit
LISTING_MODE = "hot" 
PAUSE = 1.0          # pausa

all_posts = []
for sub in SUBREDDITS:
    print(f"Descargando posts de r/{sub} ...")
    df_sub = fetch_posts(reddit, sub, limit=POSTS_PER_SUB, listing=LISTING_MODE)
    all_posts.append(df_sub)
    time.sleep(PAUSE)

# Concatenar y limpiar duplicados
posts_all_df = pd.concat(all_posts, ignore_index=True).drop_duplicates(subset=["post_id"])

print("Total de posts recolectados:", posts_all_df.shape[0])
display(posts_all_df.head(15))

# Guardar a CSV
posts_all_df.to_csv("reddit_posts_raw.csv", index=False)
print("✔ Archivo guardado: reddit_posts_raw.csv")

def fetch_comments_for_post(reddit, post_id, max_comments=5):
    """Descarga hasta max_comments comentarios de un post."""
    submission = reddit.submission(id=post_id)
    submission.comments.replace_more(limit=0) 

    rows = []
    count = 0
    for c in submission.comments.list():
        if count >= max_comments:
            break
        rows.append({
            "post_id": post_id,
            "comment_id": c.id,
            "body": c.body,
            "score": c.score,
        })
        count += 1
    return rows

# Tomamos todos los posts del DF
post_ids = posts_all_df["post_id"].tolist()

all_comments = []
for pid in post_ids:
    all_comments.extend(fetch_comments_for_post(reddit, pid, max_comments=5))

comments_df = pd.DataFrame(all_comments).drop_duplicates(subset=["comment_id"])
print("Total comentarios recolectados:", comments_df.shape)
display(comments_df.head(10))

# Guardamos en la carpeta output/
import os
os.makedirs("output", exist_ok=True)
comments_df.to_csv("output/reddit_comments.csv", index=False)
print("✔ Archivo guardado: output/reddit_comments.csv")


